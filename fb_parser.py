# fb_parser.py
import os
import logging
import time
import hashlib

from facebook_scraper import get_posts

import requests

from db import get_conn

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - fb_parser - %(levelname)s - %(message)s",
)
log = logging.getLogger("fb_parser")

API_URL = os.getenv("BOT_API") or os.getenv(
    "PARSER_API_URL",  # –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–µ –∏–º—è
    "http://localhost:8080/post",
)

CHECK_INTERVAL_MINUTES = int(os.getenv("CHECK_INTERVAL_MINUTES", "5"))

JOB_KEYWORDS = [
    kw.strip().lower()
    for kw in os.getenv(
        "JOB_KEYWORDS",
        "–≤–∞–∫–∞–Ω—Å–∏—è,—Ä–∞–±–æ—Ç–∞,job,hiring,remote,developer,–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç,amazon",
    ).split(",")
    if kw.strip()
]

FB_COOKIES = os.getenv("FB_COOKIES", "")

PAGE_LIMIT = int(os.getenv("FB_PAGE_LIMIT", "5"))


# -------------- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–æ–µ --------------


def extract_group_id(group_link: str) -> str:
    """
    –ò–∑ –ø–æ–ª–Ω–æ–≥–æ URL –≥—Ä—É–ø–ø—ã –¥–æ—Å—Ç–∞—ë–º –µ—ë slug/id –¥–ª—è facebook_scraper.
    –ü—Ä–∏–º–µ—Ä—ã:
      https://www.facebook.com/groups/ProjectAmazon -> ProjectAmazon
      https://www.facebook.com/groups/187743251645949/ -> 187743251645949
    –ï—Å–ª–∏ –ø—Ä–∏—à—ë–ª —É–∂–µ slug/id ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å.
    """
    from urllib.parse import urlparse

    parsed = urlparse(group_link)
    parts = [p for p in parsed.path.split("/") if p]

    if "groups" in parts:
        idx = parts.index("groups")
        if len(parts) > idx + 1:
            return parts[idx + 1]

    return group_link


def get_fb_groups_from_db():
    """
    –ß–∏—Ç–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä—É–ø–ø—ã –∏–∑ Postgres.
    """
    try:
        conn = get_conn()
        cur = conn.cursor()
        cur.execute(
            """
            SELECT group_id, group_name
            FROM fb_groups
            WHERE enabled = TRUE;
            """
        )
        rows = cur.fetchall()
        conn.close()
        groups = [(row["group_id"], row["group_name"]) for row in rows]
        if not groups:
            log.warning("‚ö†Ô∏è –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö FB –≥—Ä—É–ø–ø –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
        return groups
    except Exception as e:
        log.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –≥—Ä—É–ø–ø –∏–∑ –ë–î: {e}")
        return []


def make_content_hash(text: str, link: str) -> str:
    h = hashlib.sha256()
    h.update(text.encode("utf-8", errors="ignore"))
    h.update((link or "").encode("utf-8", errors="ignore"))
    return h.hexdigest()


def post_job_to_api(group_name: str, text: str, link: str):
    payload = {
        "group_name": group_name,
        "text": text,
        "link": link,
        "content_hash": make_content_hash(text, link),
        "source_type": "facebook",
    }
    try:
        resp = requests.post(API_URL, json=payload, timeout=30)
        if resp.status_code != 200:
            log.warning(f"API –≤–µ—Ä–Ω—É–ª {resp.status_code}: {resp.text}")
    except Exception as e:
        log.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ API: {e}")


# -------------- –ü–∞—Ä—Å–∏–Ω–≥ –≥—Ä—É–ø–ø—ã --------------


def parse_facebook_group(group_link: str, group_name: str) -> int:
    group_id = extract_group_id(group_link)
    log.info(f"–ü–∞—Ä—Å–∏–Ω–≥ FB –≥—Ä—É–ø–ø—ã: {group_link} (id={group_id}, pages={PAGE_LIMIT})")

    cookies = None
    if FB_COOKIES:
        # facebook_scraper –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ª–∏–±–æ dict, –ª–∏–±–æ "raw" —Å—Ç—Ä–æ–∫—É
        cookies = FB_COOKIES

    processed = 0

    try:
        for post in get_posts(
            group=group_id,
            pages=PAGE_LIMIT,
            cookies=cookies,
            options={"allow_extra_requests": True},
        ):
            text = (post.get("text") or "").strip()
            if not text:
                continue

            link = post.get("post_url") or post.get("link")

            lower = text.lower()
            if not any(kw in lower for kw in JOB_KEYWORDS):
                continue

            processed += 1
            log.info(
                f"üéØ –ù–∞–π–¥–µ–Ω –ø–æ—Å—Ç –≤ {group_name}: "
                f"{text[:80].replace(chr(10), ' ')}..."
            )
            post_job_to_api(group_name, text, link)

    except Exception as e:
        log.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –≥—Ä—É–ø–ø—ã {group_link}: {e}")

    log.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} –ø–æ—Å—Ç–æ–≤ –∏–∑ –≥—Ä—É–ø–ø—ã {group_link}")
    return processed


# -------------- –ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª --------------


def run_parser_loop():
    log.info("üöÄ –ó–∞–ø—É—Å–∫ Facebook –ø–∞—Ä—Å–µ—Ä–∞")
    log.info(f"API: {API_URL}")
    log.info(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {JOB_KEYWORDS}")
    log.info(f"Cookies: {'‚úÖ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã' if FB_COOKIES else '‚õîÔ∏è –ù–ï –∑–∞–¥–∞–Ω—ã'}")
    log.info(f"‚è∞ –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {CHECK_INTERVAL_MINUTES} –º–∏–Ω—É—Ç")

    while True:
        log.info("üîÑ –ù–∞—á–∏–Ω–∞—é —Ü–∏–∫–ª –ø–∞—Ä—Å–∏–Ω–≥–∞...")
        groups = get_fb_groups_from_db()
        total_posts = 0

        for group_link, group_name in groups:
            total_posts += parse_facebook_group(group_link, group_name)
            time.sleep(2)  # –Ω–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –≥—Ä—É–ø–ø–∞–º–∏

        log.info(f"‚úÖ –¶–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {total_posts} –ø–æ—Å—Ç–æ–≤")
        log.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {CHECK_INTERVAL_MINUTES} –º–∏–Ω—É—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏...")
        time.sleep(CHECK_INTERVAL_MINUTES * 60)


if __name__ == "__main__":
    run_parser_loop()
